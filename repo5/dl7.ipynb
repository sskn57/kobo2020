{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "畳み込みニューラルネットワーク (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNNでは各層を流れるデータは4次元(batch_num, channel, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape = (10, 1, 28, 28)\n",
      "x[0].shape = (1, 28, 28)\n",
      "x[1].shape = (1, 28, 28)\n",
      "x[9].shape = (1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#28*28, channel = 1 の画像10枚分\n",
    "x = np.random.rand(10, 1, 28, 28)\n",
    "print('x.shape = {}'.format(x.shape))\n",
    "print('x[0].shape = {}'.format(x[0].shape))\n",
    "print('x[1].shape = {}'.format(x[1].shape))\n",
    "print('x[9].shape = {}'.format(x[9].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "im2colの利用\\\n",
    "入力データの展開によって、入力データを2次元に変換する。\\\n",
    "    im2col(input_data, filter_h, filter_w, stride=1, pad=0)\\\n",
    "input_data; 入力データ(4次元配列)\\\n",
    "filter_h, filter_w; フィルターの高さ、幅\\\n",
    "stride; ストライド\\\n",
    "pad; パディング(余白)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col1.shape = (9, 75)\n",
      "col2.shape = (90, 75)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append('..')\n",
    "from common.util import im2col\n",
    "\n",
    "x1 = np.random.rand(1, 3, 7, 7) #3cahnnel,7*7, 1枚\n",
    "col1 = im2col(x1, 5, 5, stride=1, pad=0)\n",
    "print('col1.shape = {}'.format(col1.shape))\n",
    "\n",
    "x2 = np.random.rand(10, 3, 7, 7) #3cahnnel,7*7, 10枚\n",
    "col2 = im2col(x2, 5, 5, stride=1, pad=0)\n",
    "print('col2.shape = {}'.format(col2.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "75はフィルター(3channel, 5 * 5)の要素の総和である\\\n",
    "9は出力データ(3 * 3)の要素の総和である\\\n",
    "90はbatch_num分かかっている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutionレイヤの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution:\n",
    "    def __init__(self, W, b, stride=1, pad=0):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        slef.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "    def forward(self,x):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        N, C. H, W = x.shape\n",
    "        out_h = int(1 + (H + 2*self.pad - FH) / self.stride)\n",
    "        out_w = int(1 + (W + 2*self.pad - FW) / self.stride)\n",
    "        \n",
    "        #入力データの展開\n",
    "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "        #重み(フィルタ)の展開\n",
    "        col_W = self.W.reshape(FN, -1) #reshape()-1指定で(FN, a, b, c, ...)を(FN, a*b*c...)に変形\n",
    "        \n",
    "        out = np.dot(col, col_W) + self.b #()\n",
    "        print(out.shape)\n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
    "        #transpose; (N, H, W, C) -> (N, C, H, W)\n",
    "        return out\n",
    "    \n",
    "    #def backward()は省略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poolingレイヤの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        sels.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        N, C, H, N =x.shape\n",
    "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "        \n",
    "        #展開\n",
    "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.pool_h * self.pool_w) #1行がpool内全要素\n",
    "        #max\n",
    "        out = np.max(col, axis=1) #行ごとに処理\n",
    "        #reshape\n",
    "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
    "        return out\n",
    "    \n",
    "    #def backwardは省略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNNの実装\\\n",
    "SimpleConvNet\\\n",
    "層\\\n",
    "Conv - ReLU - Pooling - Affine - ReLU - Affine - Softmax\\\n",
    "引数\\\n",
    "input_dim; 入力データ(channel, height, width)の次元\\\n",
    "con_param; hyper_params(filter_num, filter_size, stride, pad)\\\n",
    "hidden_size;隠れ層のニューロン層\\\n",
    "output_size; 出力のニューロン層\\\n",
    "weight_init_std; 初期化の際の重みの標準偏差\\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConvNet:\n",
    "    def __init__(self, input_dim=(1, 28, 28), conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1}, hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num'] #30\n",
    "        filter_size = conv_param['filter_size'] #5\n",
    "        filter_pad = conv_param['pad'] #0\n",
    "        filter_stride = conv_param['stride'] #1\n",
    "        input_size = input_dim[1] #28\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad_) / filter_stride + 1 #(28 - 5 - 2*0) / 1 = 23\n",
    "        pool_output_size = int(filter_num * (conv_output_size / 2) * (conv_output_size / 2)) #int(30 * (23/2) *(23/2)) = int(3967.5) = 3968\n",
    "\n",
    "        #重みparamsの設定\n",
    "        self.params = {}\n",
    "        #layer 1\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(filter_num, input_dim[0], filter_size, filter_size) #(30, 1, 5, 5)\n",
    "        self.params['b1'] = np.zeros(filter_num) #(30)\n",
    "        #layer 2\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(pool_output_size, hidden_size) #(3968, 100)\n",
    "        self.params['b2'] = np.zeros(hidden_size) #(100)\n",
    "        #layer 3\n",
    "        self.params['W3'] = weight_init_std * np.random.randn(hidden_size, output_size) #(100, 10)\n",
    "        self.params['b3'] = np.zeros() #(10)\n",
    "\n",
    "        #layerの作成\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'], conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        #x入力データ, t教師ラベル\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        #forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        #backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        grads = {}\n",
    "        grads['W1'] = self.layers['Conv1'].dW\n",
    "        grads['b1'] = self.layers['Conv1'].db\n",
    "        grads['W2'] = self.layers['Affine1'].dW\n",
    "        grads['b2'] = self.layers['Affine1'].db\n",
    "        grads['W3'] = self.layers['Affine2'].dW\n",
    "        grads['b3'] = self.layers['Affine2'].db\n",
    "\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考文献1を読みつつコードを実装することで、理解が深まった。\\\n",
    "ここからはサンプルコードを実行してMNISTデータを学習させる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train-images-idx3-ubyte.gz ... \n",
      "Done\n",
      "Downloading train-labels-idx1-ubyte.gz ... \n",
      "Done\n",
      "Downloading t10k-images-idx3-ubyte.gz ... \n",
      "Done\n",
      "Downloading t10k-labels-idx1-ubyte.gz ... \n",
      "Done\n",
      "Converting train-images-idx3-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting train-labels-idx1-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting t10k-images-idx3-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting t10k-labels-idx1-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Creating pickle file ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from simple_convnet import SimpleConvNet\n",
    "from common.trainer import Trainer\n",
    "\n",
    "# データの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 処理に時間のかかる場合はデータを削減 \n",
    "x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 5 #20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3002398764578587\n",
      "=== epoch:1, train acc:0.149, test acc:0.126 ===\n",
      "train loss:2.298371257803771\n",
      "train loss:2.297490749480363\n",
      "train loss:2.2913744779127843\n",
      "train loss:2.2840852806787915\n",
      "train loss:2.282829351624994\n",
      "train loss:2.267165012701346\n",
      "train loss:2.261031785709768\n",
      "train loss:2.240026819601695\n",
      "train loss:2.213219709791695\n",
      "train loss:2.1996138422517735\n",
      "train loss:2.1582591387757892\n",
      "train loss:2.1262225013779172\n",
      "train loss:2.099063039589664\n",
      "train loss:2.0641097276628373\n",
      "train loss:2.003297540029907\n",
      "train loss:1.9296165504882703\n",
      "train loss:1.8757231146506053\n",
      "train loss:1.804652374122552\n",
      "train loss:1.7848511100964155\n",
      "train loss:1.5773035299715574\n",
      "train loss:1.586779889634354\n",
      "train loss:1.5598277055767718\n",
      "train loss:1.4109893751445728\n",
      "train loss:1.3177917877323344\n",
      "train loss:1.2727157834291487\n",
      "train loss:1.2104560514334282\n",
      "train loss:1.1557761485208142\n",
      "train loss:1.0777139486577232\n",
      "train loss:1.0331983871696082\n",
      "train loss:0.9648802496765242\n",
      "train loss:0.9724607835532837\n",
      "train loss:0.804433236016473\n",
      "train loss:0.813006485766103\n",
      "train loss:0.9705399401216662\n",
      "train loss:0.8692356256557439\n",
      "train loss:0.6256106903271595\n",
      "train loss:0.6270631884466563\n",
      "train loss:0.5212942013269135\n",
      "train loss:0.6998936719843399\n",
      "train loss:0.5911574984067126\n",
      "train loss:0.6026895258294257\n",
      "train loss:0.7620848598770078\n",
      "train loss:0.44469573716152516\n",
      "train loss:0.6150626367264962\n",
      "train loss:0.6121982120018182\n",
      "train loss:0.5529408701535167\n",
      "train loss:0.4391908989879029\n",
      "train loss:0.5261794966262788\n",
      "train loss:0.5174103751878654\n",
      "train loss:0.6011169196852781\n",
      "=== epoch:2, train acc:0.823, test acc:0.799 ===\n",
      "train loss:0.3894374513608463\n",
      "train loss:0.5233517168734061\n",
      "train loss:0.480301724745981\n",
      "train loss:0.5678284516255098\n",
      "train loss:0.4149766979094296\n",
      "train loss:0.3963572058910793\n",
      "train loss:0.5063528382573825\n",
      "train loss:0.5241048255147982\n",
      "train loss:0.5827440757494543\n",
      "train loss:0.33220258407494113\n",
      "train loss:0.5162140448813322\n",
      "train loss:0.5572669490719777\n",
      "train loss:0.6194503926985067\n",
      "train loss:0.5362585289701389\n",
      "train loss:0.33932319986576714\n",
      "train loss:0.3821280420905846\n",
      "train loss:0.4257819918279153\n",
      "train loss:0.30400120482136045\n",
      "train loss:0.42110325152770883\n",
      "train loss:0.26747339821127847\n",
      "train loss:0.3135706959345948\n",
      "train loss:0.2657401905505735\n",
      "train loss:0.3822652495862476\n",
      "train loss:0.3691348318023536\n",
      "train loss:0.37628858394908477\n",
      "train loss:0.5478277071219415\n",
      "train loss:0.36909348814674736\n",
      "train loss:0.35245653075788463\n",
      "train loss:0.2588946136960756\n",
      "train loss:0.27001861149718814\n",
      "train loss:0.46216809718386154\n",
      "train loss:0.5230982953042868\n",
      "train loss:0.31317000433411335\n",
      "train loss:0.358928529121618\n",
      "train loss:0.43107960283863456\n",
      "train loss:0.37842295718736374\n",
      "train loss:0.236993129167629\n",
      "train loss:0.31411274207040313\n",
      "train loss:0.31549278580804835\n",
      "train loss:0.3106567396562651\n",
      "train loss:0.349851080564607\n",
      "train loss:0.30886513478231586\n",
      "train loss:0.4335811053918021\n",
      "train loss:0.34994254217954457\n",
      "train loss:0.3883536581898506\n",
      "train loss:0.2463203625445373\n",
      "train loss:0.36619245818484897\n",
      "train loss:0.1976762149675022\n",
      "train loss:0.33189976190139237\n",
      "train loss:0.2806232210111539\n",
      "=== epoch:3, train acc:0.894, test acc:0.86 ===\n",
      "train loss:0.33022908680111135\n",
      "train loss:0.3623253378870611\n",
      "train loss:0.30470379331861464\n",
      "train loss:0.24339701437360253\n",
      "train loss:0.45571370371276515\n",
      "train loss:0.4425163085157595\n",
      "train loss:0.3314670339767538\n",
      "train loss:0.21467060251148046\n",
      "train loss:0.2512270386231021\n",
      "train loss:0.18180893521892436\n",
      "train loss:0.25515291070238366\n",
      "train loss:0.20704449926108506\n",
      "train loss:0.285110761493113\n",
      "train loss:0.24901023425642638\n",
      "train loss:0.19159841869649452\n",
      "train loss:0.36477164350767205\n",
      "train loss:0.24073126390567814\n",
      "train loss:0.15491794678376944\n",
      "train loss:0.3998355121488888\n",
      "train loss:0.40958852906896637\n",
      "train loss:0.3286352482460609\n",
      "train loss:0.288113568240553\n",
      "train loss:0.19408855884439422\n",
      "train loss:0.18845793409202594\n",
      "train loss:0.24995160002567984\n",
      "train loss:0.23972037804912316\n",
      "train loss:0.3111362328531282\n",
      "train loss:0.3826354900511821\n",
      "train loss:0.3790249099754607\n",
      "train loss:0.28939773534304014\n",
      "train loss:0.23224857148661537\n",
      "train loss:0.21495576135708266\n",
      "train loss:0.3606905381061965\n",
      "train loss:0.30931481117809156\n",
      "train loss:0.3898602982189508\n",
      "train loss:0.3218107139133851\n",
      "train loss:0.24363318854220523\n",
      "train loss:0.29006730273414666\n",
      "train loss:0.26601635182617217\n",
      "train loss:0.25343758444384995\n",
      "train loss:0.27810883405567727\n",
      "train loss:0.2758341049822898\n",
      "train loss:0.25271311470315977\n",
      "train loss:0.18860087231769934\n",
      "train loss:0.2813837538438274\n",
      "train loss:0.3166747781122752\n",
      "train loss:0.2754208787374985\n",
      "train loss:0.3269001472821183\n",
      "train loss:0.2330324808304796\n",
      "train loss:0.2542135414269276\n",
      "=== epoch:4, train acc:0.894, test acc:0.889 ===\n",
      "train loss:0.2961565901540628\n",
      "train loss:0.2111657935425551\n",
      "train loss:0.22894845821923393\n",
      "train loss:0.294691050118923\n",
      "train loss:0.37876683094317015\n",
      "train loss:0.18630523517829078\n",
      "train loss:0.26364676564731615\n",
      "train loss:0.19623272259535784\n",
      "train loss:0.26760181777546665\n",
      "train loss:0.23688132011728447\n",
      "train loss:0.2208310694797467\n",
      "train loss:0.36196609469840996\n",
      "train loss:0.18751939396186224\n",
      "train loss:0.20732850627594368\n",
      "train loss:0.2822274757516292\n",
      "train loss:0.22026930874091943\n",
      "train loss:0.2847593552201267\n",
      "train loss:0.2145252086268411\n",
      "train loss:0.21753731386804007\n",
      "train loss:0.22479880042322545\n",
      "train loss:0.23060541661229908\n",
      "train loss:0.26207274518829804\n",
      "train loss:0.26304539327246945\n",
      "train loss:0.265011284285533\n",
      "train loss:0.32936660313643246\n",
      "train loss:0.1551198585042643\n",
      "train loss:0.22128990578645286\n",
      "train loss:0.3117470056768783\n",
      "train loss:0.3518522300891619\n",
      "train loss:0.17239523585046612\n",
      "train loss:0.2088836195827109\n",
      "train loss:0.3071236637059975\n",
      "train loss:0.3541931926519609\n",
      "train loss:0.22602068028904224\n",
      "train loss:0.19959759352008621\n",
      "train loss:0.33208702238310084\n",
      "train loss:0.16361117391779778\n",
      "train loss:0.2361653514259209\n",
      "train loss:0.23432337902417877\n",
      "train loss:0.35011069514155124\n",
      "train loss:0.24417332400197422\n",
      "train loss:0.12342612418578143\n",
      "train loss:0.20697458466012236\n",
      "train loss:0.15459774330693032\n",
      "train loss:0.39340882774492025\n",
      "train loss:0.19806970891314826\n",
      "train loss:0.18907710975224873\n",
      "train loss:0.10811796032014893\n",
      "train loss:0.1959144009805292\n",
      "train loss:0.1970810634137705\n",
      "=== epoch:5, train acc:0.922, test acc:0.907 ===\n",
      "train loss:0.2206487713899954\n",
      "train loss:0.2659169088702026\n",
      "train loss:0.16217547585286396\n",
      "train loss:0.1336982771229148\n",
      "train loss:0.15547399621412883\n",
      "train loss:0.29990161906922463\n",
      "train loss:0.09445541206586835\n",
      "train loss:0.2341655041398695\n",
      "train loss:0.2350408308192391\n",
      "train loss:0.1622851485697376\n",
      "train loss:0.25287337268939825\n",
      "train loss:0.1480181133174695\n",
      "train loss:0.1833066547591573\n",
      "train loss:0.22810352699788747\n",
      "train loss:0.18935654556029097\n",
      "train loss:0.25311226261989245\n",
      "train loss:0.1725742260671964\n",
      "train loss:0.24255539036982515\n",
      "train loss:0.37092525796729026\n",
      "train loss:0.2642269127415739\n",
      "train loss:0.2189545978703816\n",
      "train loss:0.21110438644029428\n",
      "train loss:0.15492106646978918\n",
      "train loss:0.23705774683686465\n",
      "train loss:0.18912092664613753\n",
      "train loss:0.07113442922296864\n",
      "train loss:0.1509486853352079\n",
      "train loss:0.1580083721467499\n",
      "train loss:0.23923823892496066\n",
      "train loss:0.09403039638183691\n",
      "train loss:0.09777849311170676\n",
      "train loss:0.20170618198840515\n",
      "train loss:0.18596664910619143\n",
      "train loss:0.13492950379270865\n",
      "train loss:0.08078907205637727\n",
      "train loss:0.21801404046403902\n",
      "train loss:0.18848960061859654\n",
      "train loss:0.4223913904958335\n",
      "train loss:0.10473988468561467\n",
      "train loss:0.15468525269414748\n",
      "train loss:0.11756784343593124\n",
      "train loss:0.19691204346731392\n",
      "train loss:0.21720382692025703\n",
      "train loss:0.08899750034534519\n",
      "train loss:0.21061958898809835\n",
      "train loss:0.14086900521720058\n",
      "train loss:0.07624942009576152\n",
      "train loss:0.17592474363546262\n",
      "train loss:0.2082666117543689\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.902\n",
      "Saved Network Parameters!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# パラメータの保存\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# グラフの描画\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracyの値を見ると、エポックが大きくなるほどaccuracyも大きくなっていて、最終的に0.9近くまで行っている。trainとtestで大きな乖離がないことから過学習も起きていないと判断できる。この規模でのニューラルネットで90%程度の精度があるのに注目したい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "感想\\\n",
    "今回は畳み込みニューラルネットワークについて学習した。行列を展開して形状を変化させることで内積計算に帰着できることに驚いた。考えた人は本当に賢いなと感じた。また、ローカルで自分のPC上で実行したが、計算に時間がかかるようになってきた。\\\n",
    "今回で合同の輪読会は終了だが、ここで学んだことを自然言語処理に応用できるようしっかり復習したい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考文献\n",
    "1. ゼロから作るDeep Learning -Pythonで学ぶディープランニングの理論と実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
