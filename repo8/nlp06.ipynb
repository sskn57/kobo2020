{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ゲート付きRNN**\\\n",
    "前回学んだRNNLMの手法では勾配消失と勾配爆発が起こりうる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**勾配爆発への対策**\\\n",
    "勾配クリッピングと呼ばれる手法を用いることで解決"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_grads(grads, max_norm):\n",
    "    total_norm = 0\n",
    "    for grad in grads:\n",
    "        total_norm += np.sum(grad ** 2)\n",
    "    total = np.sqrt(total_norm)\n",
    "    rate = max_norm / (total_norm + 1e-6)\n",
    "    if rate < 1:\n",
    "        for grad in grads:\n",
    "            grad *= rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grads\n",
      "[array([[2.91585734, 4.52160871, 8.90171233],\n",
      "       [3.77552663, 8.32342898, 8.86643038],\n",
      "       [0.62323374, 6.49377253, 7.46412909]]), array([[6.70676984, 2.52376535, 0.64094627],\n",
      "       [6.23686218, 8.78568207, 9.41419369],\n",
      "       [6.19644341, 7.32474617, 4.19842518]])]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "grads (clip_grads)\n",
      "[array([[0.01984237, 0.03076949, 0.06057603],\n",
      "       [0.02569241, 0.05664082, 0.06033594],\n",
      "       [0.0042411 , 0.04419004, 0.0507933 ]]), array([[0.04563948, 0.01717419, 0.00436163],\n",
      "       [0.04244176, 0.05978645, 0.06406346],\n",
      "       [0.04216671, 0.0498448 , 0.02857023]])]\n"
     ]
    }
   ],
   "source": [
    "dW1 = np.random.rand(3, 3) * 10\n",
    "dW2 = np.random.rand(3, 3) * 10\n",
    "grads = [dW1, dW2]\n",
    "max_norm = 5.0\n",
    "print('grads')\n",
    "print(grads)\n",
    "print('-'*100)\n",
    "clip_grads(grads, max_norm)\n",
    "print('grads (clip_grads)')\n",
    "print(grads)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**勾配消失への対策**\\\n",
    "勾配消失への対策はゲート付きRNNレイヤを用いる。今回はゲート付きRNNの中でLSTMを考える。\\\n",
    "なお、ゲートはsigmoid関数で表せる。sigmoid()関数は0.0~0.1の値を出力するので出力する割合を設定できる。つまり、ゲートを通すことでそのパラメータの重要度を設定できる。\\\n",
    "各時系列ごとのRNNレイヤは記憶セルcを持ち、記憶セルcから隠れ状態が計算される。\\\n",
    "\\\n",
    "まず、出力$h_t$を考える。\\\n",
    "$h_t$は記憶セル$c_t$から計算される。この$tanh(c_t)$の計算にoutputゲート$o$を適用する。$o$と$tanh(c_t)$の要素ごとの積(アダマール積)を出力とする。\n",
    "$$h_t=o * tanh(c_t)$$\n",
    "$$o=sigmoid(x_tW_x^{(o)}+h_{t-1}W_h^{(o)}+b^{(o)})$$\n",
    "\\\n",
    "次に$c_t$の計算c()を考える。\\\n",
    "$$c_t=c(c_{t-1}, h_{t-1}, x_t)$$\n",
    "まず、$c_{t-1}$をそのまま利用するのではなく不要な情報を忘れさせるためのforgetゲートが必要。このゲートの重み$f$は以下のようになる。\n",
    "$$f=sigmoid(x_tW_x^{(f)}+h_{t-1}W_h^{(f)}+b^{(f)})$$\n",
    "次に、記憶セルに新しく覚えさせるための処理を考える。「情報」の処理なので活性化関数にtanhを用いる。新しい記憶は$g$で表す。\n",
    "$$g=tanh(x_tW_x^{(g)}+h_{t-1}W_h^{(g)}+b^{(g)})$$\n",
    "この$g$にinputゲート$i$を通す。\n",
    "$$i=sigmoid(x_tW_x^{(i)}+h_{t-1}W_h^{(i)}+b^{(i)})$$\n",
    "以上より$c_t$は以下のように表せる。\n",
    "$$c_t=f * c_{t-1} + i * g$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSTMの実装**\\\n",
    "$o$, $f$, $g$, $i$はアフィン変換を行っている。\\\n",
    "線形性より4つの重みを一つにまとめることができる。\n",
    "$$x_tW_x^{(f)}+h_{t-1}W_h^{(f)}+b^{(f)}$$\n",
    "$$x_tW_x^{(g)}+h_{t-1}W_h^{(g)}+b^{(g)}$$\n",
    "$$x_tW_x^{(i)}+h_{t-1}W_h^{(i)}+b^{(i)}$$\n",
    "$$x_tW_x^{(o)}+h_{t-1}W_h^{(o)}+b^{(o)}$$\n",
    "\\\n",
    "$$x_t[W_x^{(f)}+W_x^{(g)}+W_x^{(i)}+W_x^{(o)}]+h_{t-1}[ W_h^{(f)}+W_h^{(g)}+W_h^{(i)}+W_h^{(o)} ]+[b^{(f)}+b^{(g)}+b^{(i)}+b^{(o)}]$$\n",
    "\\\n",
    "$$x_tW_x + h_{t-1}W_h + b$$\n",
    "したがってまず重み全体をアフィン変換し、そこからsliceノードによって4つに分けて取り出す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM:\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.cache = None\n",
    "        \n",
    "    def forward(self, x, h_prev, c_prev):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, H = h_prev.shape\n",
    "        \n",
    "        # Affine変換\n",
    "        A = np.dot(x, Wx) + np.dot(h_prev, Wh) + b\n",
    "        \n",
    "        # slice\n",
    "        f = A[:, :H]\n",
    "        g = A[:, H:2*H]\n",
    "        i = A[:, 2*H:3*H]\n",
    "        o = A[:, 3*H:]\n",
    "        \n",
    "        # sigmoid\n",
    "        f = sigmoid(f)\n",
    "        g = sigmoid(g)\n",
    "        i = sigmoid(i)\n",
    "        o = sigmoid(o)\n",
    "        \n",
    "        c_next = f * c_prev + i * g\n",
    "        h_next = o * np.tanh(c_next)\n",
    "        \n",
    "        self.cache = (x, h_prev, c_prev, i, f, g, o, c_next)\n",
    "        return h_next, c_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TIME LSTMレイヤの実装**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeLSTM:\n",
    "    def __init__(self, Wx, Wh, b, stateful=False):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "        \n",
    "        self.h, self.c = None, None\n",
    "        self.dh = None\n",
    "        self.stateful = stateful\n",
    "        \n",
    "    def forward(self, xs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = xs.shape # N;batch, T;時系列データ数, D;各時系列データ(入力)次元数\n",
    "        H = Wh.shape[0]\n",
    "        \n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f')\n",
    "        \n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N, H), dtype='f')\n",
    "        if not self.stateful or self.c is None:\n",
    "            self.c = np.zeros((N, H), dtype='f')\n",
    "        \n",
    "        for t in range(T):\n",
    "            later = LSTM(*self.params)\n",
    "            self.h, self.c = layer.forward(xs[:, t, :], self.h, self.c)\n",
    "            hs[:, t, :] = self.h\n",
    "            \n",
    "            self.layers.append(layer)\n",
    "            \n",
    "        return hs\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, H = dhs.shape # N;batch, T;時系列データ数, H;各時系列データ(出力)次元数\n",
    "        D = Wx.shape[0]\n",
    "        \n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh, dc = 0, 0\n",
    "        \n",
    "        grads = [0, 0, 0]\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh, dc = layer.backward(dhs[:, t, :] + dh, dc)\n",
    "            dxs[:, t, :] = dx\n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "        \n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "        self.dh = dh\n",
    "        return dxs\n",
    "    \n",
    "    def set_state(self, h, c=None):\n",
    "        self.h, self.c = h, c\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.h, self.c = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSTMを用いた言語モデル**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.time_layers import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rnnlm:\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=100, hidden_size=100):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        \n",
    "        # 重みの初期化\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "        \n",
    "        # レイヤの生成\n",
    "        self.layers = {\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        }\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layer = self.layers[1]\n",
    "        \n",
    "        # 全ての重みと勾配をリストにまとめる\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "            \n",
    "    def predict(self, xs):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "    \n",
    "    def forward(self, xs, ts):\n",
    "        score = self.predict(xs)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.lstm_layer.reset_state()\n",
    "    \n",
    "    def save_params(self, file_name='Rnnlm.pkl'):\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(self.params, f)\n",
    "    \n",
    "    def load_params(self, file_name='Rnnlm'):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            self.params = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PTBデータセットの学習**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from common.util import eval_perplexity\n",
    "from dataset import ptb\n",
    "from rnnlm import Rnnlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ptb.train.txt ... \n",
      "Done\n",
      "Downloading ptb.test.txt ... \n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# ハイパーパラメータの設定\n",
    "batch_size = 20\n",
    "wordvec_size = 100\n",
    "hidden_size = 100 # RNNの隠れ状態ベクトルの要素数\n",
    "time_size = 35 #RNNの展開サイズ\n",
    "lr = 20.0\n",
    "max_epoch = 4\n",
    "max_grad = 0.25\n",
    "\n",
    "#学習データの読み込み\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_test, _, _ = ptb.load_data('test')\n",
    "vocab_size = len(word_to_id)\n",
    "xs = corpus[:-1]\n",
    "ts = corpus[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの生成\n",
    "model = Rnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 |  iter 1 / 1327 | time 0[s] | perplexity 10000.89\n",
      "| epoch 1 |  iter 21 / 1327 | time 10[s] | perplexity 3075.13\n",
      "| epoch 1 |  iter 41 / 1327 | time 24[s] | perplexity 1226.72\n",
      "| epoch 1 |  iter 61 / 1327 | time 37[s] | perplexity 989.04\n",
      "| epoch 1 |  iter 81 / 1327 | time 50[s] | perplexity 823.01\n",
      "| epoch 1 |  iter 101 / 1327 | time 63[s] | perplexity 662.78\n",
      "| epoch 1 |  iter 121 / 1327 | time 77[s] | perplexity 666.56\n",
      "| epoch 1 |  iter 141 / 1327 | time 92[s] | perplexity 597.56\n",
      "| epoch 1 |  iter 161 / 1327 | time 105[s] | perplexity 571.22\n",
      "| epoch 1 |  iter 181 / 1327 | time 118[s] | perplexity 585.68\n",
      "| epoch 1 |  iter 201 / 1327 | time 132[s] | perplexity 505.34\n",
      "| epoch 1 |  iter 221 / 1327 | time 145[s] | perplexity 496.20\n",
      "| epoch 1 |  iter 241 / 1327 | time 158[s] | perplexity 439.43\n",
      "| epoch 1 |  iter 261 / 1327 | time 172[s] | perplexity 456.37\n",
      "| epoch 1 |  iter 281 / 1327 | time 185[s] | perplexity 444.46\n",
      "| epoch 1 |  iter 301 / 1327 | time 198[s] | perplexity 398.18\n",
      "| epoch 1 |  iter 321 / 1327 | time 211[s] | perplexity 351.25\n",
      "| epoch 1 |  iter 341 / 1327 | time 224[s] | perplexity 404.94\n",
      "| epoch 1 |  iter 361 / 1327 | time 237[s] | perplexity 405.55\n",
      "| epoch 1 |  iter 381 / 1327 | time 250[s] | perplexity 334.69\n",
      "| epoch 1 |  iter 401 / 1327 | time 265[s] | perplexity 354.01\n",
      "| epoch 1 |  iter 421 / 1327 | time 278[s] | perplexity 346.67\n",
      "| epoch 1 |  iter 441 / 1327 | time 291[s] | perplexity 332.57\n",
      "| epoch 1 |  iter 461 / 1327 | time 304[s] | perplexity 334.27\n",
      "| epoch 1 |  iter 481 / 1327 | time 318[s] | perplexity 307.06\n",
      "| epoch 1 |  iter 501 / 1327 | time 331[s] | perplexity 311.07\n",
      "| epoch 1 |  iter 521 / 1327 | time 346[s] | perplexity 303.85\n",
      "| epoch 1 |  iter 541 / 1327 | time 359[s] | perplexity 317.42\n",
      "| epoch 1 |  iter 561 / 1327 | time 372[s] | perplexity 291.89\n",
      "| epoch 1 |  iter 581 / 1327 | time 386[s] | perplexity 257.31\n",
      "| epoch 1 |  iter 601 / 1327 | time 399[s] | perplexity 339.53\n",
      "| epoch 1 |  iter 621 / 1327 | time 412[s] | perplexity 314.17\n",
      "| epoch 1 |  iter 641 / 1327 | time 425[s] | perplexity 284.17\n",
      "| epoch 1 |  iter 661 / 1327 | time 438[s] | perplexity 274.10\n",
      "| epoch 1 |  iter 681 / 1327 | time 451[s] | perplexity 226.33\n",
      "| epoch 1 |  iter 701 / 1327 | time 464[s] | perplexity 249.61\n",
      "| epoch 1 |  iter 721 / 1327 | time 478[s] | perplexity 261.96\n",
      "| epoch 1 |  iter 741 / 1327 | time 492[s] | perplexity 221.97\n",
      "| epoch 1 |  iter 761 / 1327 | time 505[s] | perplexity 239.24\n",
      "| epoch 1 |  iter 781 / 1327 | time 518[s] | perplexity 221.99\n",
      "| epoch 1 |  iter 801 / 1327 | time 531[s] | perplexity 243.89\n",
      "| epoch 1 |  iter 821 / 1327 | time 544[s] | perplexity 227.48\n",
      "| epoch 1 |  iter 841 / 1327 | time 559[s] | perplexity 231.18\n",
      "| epoch 1 |  iter 861 / 1327 | time 573[s] | perplexity 223.17\n",
      "| epoch 1 |  iter 881 / 1327 | time 586[s] | perplexity 208.96\n",
      "| epoch 1 |  iter 901 / 1327 | time 599[s] | perplexity 255.14\n",
      "| epoch 1 |  iter 921 / 1327 | time 612[s] | perplexity 230.67\n",
      "| epoch 1 |  iter 941 / 1327 | time 626[s] | perplexity 230.95\n",
      "| epoch 1 |  iter 961 / 1327 | time 639[s] | perplexity 247.93\n",
      "| epoch 1 |  iter 981 / 1327 | time 652[s] | perplexity 230.92\n",
      "| epoch 1 |  iter 1001 / 1327 | time 665[s] | perplexity 194.74\n",
      "| epoch 1 |  iter 1021 / 1327 | time 679[s] | perplexity 229.06\n",
      "| epoch 1 |  iter 1041 / 1327 | time 692[s] | perplexity 209.69\n",
      "| epoch 1 |  iter 1061 / 1327 | time 705[s] | perplexity 198.41\n",
      "| epoch 1 |  iter 1081 / 1327 | time 718[s] | perplexity 170.28\n",
      "| epoch 1 |  iter 1101 / 1327 | time 731[s] | perplexity 192.86\n",
      "| epoch 1 |  iter 1121 / 1327 | time 744[s] | perplexity 228.19\n",
      "| epoch 1 |  iter 1141 / 1327 | time 758[s] | perplexity 208.31\n",
      "| epoch 1 |  iter 1161 / 1327 | time 772[s] | perplexity 200.09\n",
      "| epoch 1 |  iter 1181 / 1327 | time 786[s] | perplexity 191.63\n",
      "| epoch 1 |  iter 1201 / 1327 | time 800[s] | perplexity 163.58\n",
      "| epoch 1 |  iter 1221 / 1327 | time 813[s] | perplexity 159.24\n",
      "| epoch 1 |  iter 1241 / 1327 | time 826[s] | perplexity 189.42\n",
      "| epoch 1 |  iter 1261 / 1327 | time 839[s] | perplexity 172.86\n",
      "| epoch 1 |  iter 1281 / 1327 | time 853[s] | perplexity 179.32\n",
      "| epoch 1 |  iter 1301 / 1327 | time 866[s] | perplexity 222.67\n",
      "| epoch 1 |  iter 1321 / 1327 | time 879[s] | perplexity 211.62\n",
      "| epoch 2 |  iter 1 / 1327 | time 884[s] | perplexity 226.08\n",
      "| epoch 2 |  iter 21 / 1327 | time 897[s] | perplexity 203.94\n",
      "| epoch 2 |  iter 41 / 1327 | time 910[s] | perplexity 191.47\n",
      "| epoch 2 |  iter 61 / 1327 | time 923[s] | perplexity 177.44\n",
      "| epoch 2 |  iter 81 / 1327 | time 936[s] | perplexity 159.19\n",
      "| epoch 2 |  iter 101 / 1327 | time 950[s] | perplexity 152.18\n",
      "| epoch 2 |  iter 121 / 1327 | time 963[s] | perplexity 159.82\n",
      "| epoch 2 |  iter 141 / 1327 | time 976[s] | perplexity 178.73\n",
      "| epoch 2 |  iter 161 / 1327 | time 990[s] | perplexity 192.81\n",
      "| epoch 2 |  iter 181 / 1327 | time 1003[s] | perplexity 201.55\n",
      "| epoch 2 |  iter 201 / 1327 | time 1019[s] | perplexity 184.84\n",
      "| epoch 2 |  iter 221 / 1327 | time 1032[s] | perplexity 182.95\n",
      "| epoch 2 |  iter 241 / 1327 | time 1045[s] | perplexity 177.74\n",
      "| epoch 2 |  iter 261 / 1327 | time 1058[s] | perplexity 186.20\n",
      "| epoch 2 |  iter 281 / 1327 | time 1070[s] | perplexity 186.02\n",
      "| epoch 2 |  iter 301 / 1327 | time 1083[s] | perplexity 167.49\n",
      "| epoch 2 |  iter 321 / 1327 | time 1096[s] | perplexity 138.61\n",
      "| epoch 2 |  iter 341 / 1327 | time 1110[s] | perplexity 172.96\n",
      "| epoch 2 |  iter 361 / 1327 | time 1122[s] | perplexity 198.24\n",
      "| epoch 2 |  iter 381 / 1327 | time 1135[s] | perplexity 155.85\n",
      "| epoch 2 |  iter 401 / 1327 | time 1147[s] | perplexity 169.71\n",
      "| epoch 2 |  iter 421 / 1327 | time 1162[s] | perplexity 158.20\n",
      "| epoch 2 |  iter 441 / 1327 | time 1177[s] | perplexity 164.46\n",
      "| epoch 2 |  iter 461 / 1327 | time 1192[s] | perplexity 158.16\n",
      "| epoch 2 |  iter 481 / 1327 | time 1208[s] | perplexity 156.39\n",
      "| epoch 2 |  iter 501 / 1327 | time 1221[s] | perplexity 171.10\n",
      "| epoch 2 |  iter 521 / 1327 | time 1234[s] | perplexity 173.35\n",
      "| epoch 2 |  iter 541 / 1327 | time 1247[s] | perplexity 177.01\n",
      "| epoch 2 |  iter 561 / 1327 | time 1260[s] | perplexity 156.06\n",
      "| epoch 2 |  iter 581 / 1327 | time 1273[s] | perplexity 138.50\n",
      "| epoch 2 |  iter 601 / 1327 | time 1287[s] | perplexity 193.46\n",
      "| epoch 2 |  iter 621 / 1327 | time 1301[s] | perplexity 182.79\n",
      "| epoch 2 |  iter 641 / 1327 | time 1314[s] | perplexity 164.30\n",
      "| epoch 2 |  iter 661 / 1327 | time 1327[s] | perplexity 155.56\n",
      "| epoch 2 |  iter 681 / 1327 | time 1340[s] | perplexity 131.25\n",
      "| epoch 2 |  iter 701 / 1327 | time 1353[s] | perplexity 152.61\n",
      "| epoch 2 |  iter 721 / 1327 | time 1366[s] | perplexity 160.85\n",
      "| epoch 2 |  iter 741 / 1327 | time 1379[s] | perplexity 134.92\n",
      "| epoch 2 |  iter 761 / 1327 | time 1392[s] | perplexity 132.82\n",
      "| epoch 2 |  iter 781 / 1327 | time 1405[s] | perplexity 136.75\n",
      "| epoch 2 |  iter 801 / 1327 | time 1419[s] | perplexity 149.90\n",
      "| epoch 2 |  iter 821 / 1327 | time 1431[s] | perplexity 145.75\n",
      "| epoch 2 |  iter 841 / 1327 | time 1445[s] | perplexity 145.57\n",
      "| epoch 2 |  iter 861 / 1327 | time 1458[s] | perplexity 145.62\n",
      "| epoch 2 |  iter 881 / 1327 | time 1471[s] | perplexity 131.23\n",
      "| epoch 2 |  iter 901 / 1327 | time 1484[s] | perplexity 167.54\n",
      "| epoch 2 |  iter 921 / 1327 | time 1497[s] | perplexity 146.90\n",
      "| epoch 2 |  iter 941 / 1327 | time 1510[s] | perplexity 155.07\n",
      "| epoch 2 |  iter 961 / 1327 | time 1524[s] | perplexity 164.83\n",
      "| epoch 2 |  iter 981 / 1327 | time 1537[s] | perplexity 155.04\n",
      "| epoch 2 |  iter 1001 / 1327 | time 1550[s] | perplexity 132.37\n",
      "| epoch 2 |  iter 1021 / 1327 | time 1563[s] | perplexity 158.59\n",
      "| epoch 2 |  iter 1041 / 1327 | time 1577[s] | perplexity 144.11\n",
      "| epoch 2 |  iter 1061 / 1327 | time 1590[s] | perplexity 129.66\n",
      "| epoch 2 |  iter 1081 / 1327 | time 1603[s] | perplexity 112.19\n",
      "| epoch 2 |  iter 1101 / 1327 | time 1615[s] | perplexity 122.06\n",
      "| epoch 2 |  iter 1121 / 1327 | time 1629[s] | perplexity 154.05\n",
      "| epoch 2 |  iter 1141 / 1327 | time 1641[s] | perplexity 142.28\n",
      "| epoch 2 |  iter 1161 / 1327 | time 1659[s] | perplexity 133.82\n",
      "| epoch 2 |  iter 1181 / 1327 | time 1675[s] | perplexity 135.20\n",
      "| epoch 2 |  iter 1201 / 1327 | time 1689[s] | perplexity 113.11\n",
      "| epoch 2 |  iter 1221 / 1327 | time 1704[s] | perplexity 109.86\n",
      "| epoch 2 |  iter 1241 / 1327 | time 1720[s] | perplexity 131.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 2 |  iter 1261 / 1327 | time 1734[s] | perplexity 123.31\n",
      "| epoch 2 |  iter 1281 / 1327 | time 1748[s] | perplexity 122.90\n",
      "| epoch 2 |  iter 1301 / 1327 | time 1763[s] | perplexity 158.88\n",
      "| epoch 2 |  iter 1321 / 1327 | time 1778[s] | perplexity 153.35\n",
      "| epoch 3 |  iter 1 / 1327 | time 1783[s] | perplexity 160.90\n",
      "| epoch 3 |  iter 21 / 1327 | time 1796[s] | perplexity 145.05\n",
      "| epoch 3 |  iter 41 / 1327 | time 1810[s] | perplexity 135.47\n",
      "| epoch 3 |  iter 61 / 1327 | time 1824[s] | perplexity 128.59\n",
      "| epoch 3 |  iter 81 / 1327 | time 1838[s] | perplexity 118.61\n",
      "| epoch 3 |  iter 101 / 1327 | time 1852[s] | perplexity 106.30\n",
      "| epoch 3 |  iter 121 / 1327 | time 1866[s] | perplexity 116.42\n",
      "| epoch 3 |  iter 141 / 1327 | time 1880[s] | perplexity 126.48\n",
      "| epoch 3 |  iter 161 / 1327 | time 1894[s] | perplexity 143.25\n",
      "| epoch 3 |  iter 181 / 1327 | time 1907[s] | perplexity 151.57\n",
      "| epoch 3 |  iter 201 / 1327 | time 1920[s] | perplexity 141.09\n",
      "| epoch 3 |  iter 221 / 1327 | time 1934[s] | perplexity 141.11\n",
      "| epoch 3 |  iter 241 / 1327 | time 1948[s] | perplexity 135.63\n",
      "| epoch 3 |  iter 261 / 1327 | time 1961[s] | perplexity 140.20\n",
      "| epoch 3 |  iter 281 / 1327 | time 1974[s] | perplexity 143.47\n",
      "| epoch 3 |  iter 301 / 1327 | time 1988[s] | perplexity 125.46\n",
      "| epoch 3 |  iter 321 / 1327 | time 2002[s] | perplexity 102.98\n",
      "| epoch 3 |  iter 341 / 1327 | time 2016[s] | perplexity 125.69\n",
      "| epoch 3 |  iter 361 / 1327 | time 2031[s] | perplexity 153.52\n",
      "| epoch 3 |  iter 381 / 1327 | time 2045[s] | perplexity 117.35\n",
      "| epoch 3 |  iter 401 / 1327 | time 2059[s] | perplexity 131.16\n",
      "| epoch 3 |  iter 421 / 1327 | time 2073[s] | perplexity 116.44\n",
      "| epoch 3 |  iter 441 / 1327 | time 2087[s] | perplexity 124.83\n",
      "| epoch 3 |  iter 461 / 1327 | time 2101[s] | perplexity 119.85\n",
      "| epoch 3 |  iter 481 / 1327 | time 2116[s] | perplexity 119.48\n",
      "| epoch 3 |  iter 501 / 1327 | time 2130[s] | perplexity 131.07\n",
      "| epoch 3 |  iter 521 / 1327 | time 2146[s] | perplexity 138.26\n",
      "| epoch 3 |  iter 541 / 1327 | time 2160[s] | perplexity 138.38\n",
      "| epoch 3 |  iter 561 / 1327 | time 2173[s] | perplexity 117.93\n",
      "| epoch 3 |  iter 581 / 1327 | time 2187[s] | perplexity 106.35\n",
      "| epoch 3 |  iter 601 / 1327 | time 2202[s] | perplexity 151.96\n",
      "| epoch 3 |  iter 621 / 1327 | time 2215[s] | perplexity 144.54\n",
      "| epoch 3 |  iter 641 / 1327 | time 2232[s] | perplexity 129.36\n",
      "| epoch 3 |  iter 661 / 1327 | time 2247[s] | perplexity 121.75\n",
      "| epoch 3 |  iter 681 / 1327 | time 2260[s] | perplexity 100.72\n",
      "| epoch 3 |  iter 701 / 1327 | time 2274[s] | perplexity 119.53\n",
      "| epoch 3 |  iter 721 / 1327 | time 2288[s] | perplexity 126.34\n",
      "| epoch 3 |  iter 741 / 1327 | time 2302[s] | perplexity 109.21\n",
      "| epoch 3 |  iter 761 / 1327 | time 2315[s] | perplexity 104.33\n",
      "| epoch 3 |  iter 781 / 1327 | time 2329[s] | perplexity 104.74\n",
      "| epoch 3 |  iter 801 / 1327 | time 2343[s] | perplexity 117.35\n",
      "| epoch 3 |  iter 821 / 1327 | time 2358[s] | perplexity 117.57\n",
      "| epoch 3 |  iter 841 / 1327 | time 2373[s] | perplexity 114.41\n",
      "| epoch 3 |  iter 861 / 1327 | time 2387[s] | perplexity 120.65\n",
      "| epoch 3 |  iter 881 / 1327 | time 2402[s] | perplexity 106.42\n",
      "| epoch 3 |  iter 901 / 1327 | time 2416[s] | perplexity 133.07\n",
      "| epoch 3 |  iter 921 / 1327 | time 2430[s] | perplexity 120.12\n",
      "| epoch 3 |  iter 941 / 1327 | time 2444[s] | perplexity 129.09\n",
      "| epoch 3 |  iter 961 / 1327 | time 2459[s] | perplexity 132.42\n",
      "| epoch 3 |  iter 981 / 1327 | time 2474[s] | perplexity 124.21\n",
      "| epoch 3 |  iter 1001 / 1327 | time 2487[s] | perplexity 108.81\n",
      "| epoch 3 |  iter 1021 / 1327 | time 2502[s] | perplexity 130.29\n",
      "| epoch 3 |  iter 1041 / 1327 | time 2517[s] | perplexity 119.36\n",
      "| epoch 3 |  iter 1061 / 1327 | time 2532[s] | perplexity 103.74\n",
      "| epoch 3 |  iter 1081 / 1327 | time 2546[s] | perplexity 89.91\n",
      "| epoch 3 |  iter 1101 / 1327 | time 2561[s] | perplexity 95.86\n",
      "| epoch 3 |  iter 1121 / 1327 | time 2576[s] | perplexity 122.04\n",
      "| epoch 3 |  iter 1141 / 1327 | time 2591[s] | perplexity 114.12\n",
      "| epoch 3 |  iter 1161 / 1327 | time 2605[s] | perplexity 106.10\n",
      "| epoch 3 |  iter 1181 / 1327 | time 2619[s] | perplexity 111.31\n",
      "| epoch 3 |  iter 1201 / 1327 | time 2634[s] | perplexity 94.50\n",
      "| epoch 3 |  iter 1221 / 1327 | time 2649[s] | perplexity 89.00\n",
      "| epoch 3 |  iter 1241 / 1327 | time 2662[s] | perplexity 106.37\n",
      "| epoch 3 |  iter 1261 / 1327 | time 2676[s] | perplexity 104.97\n",
      "| epoch 3 |  iter 1281 / 1327 | time 2689[s] | perplexity 100.42\n",
      "| epoch 3 |  iter 1301 / 1327 | time 2702[s] | perplexity 130.57\n",
      "| epoch 3 |  iter 1321 / 1327 | time 2715[s] | perplexity 126.96\n",
      "| epoch 4 |  iter 1 / 1327 | time 2720[s] | perplexity 132.88\n",
      "| epoch 4 |  iter 21 / 1327 | time 2733[s] | perplexity 122.97\n",
      "| epoch 4 |  iter 41 / 1327 | time 2747[s] | perplexity 106.65\n",
      "| epoch 4 |  iter 61 / 1327 | time 2761[s] | perplexity 108.38\n",
      "| epoch 4 |  iter 81 / 1327 | time 2774[s] | perplexity 96.94\n",
      "| epoch 4 |  iter 101 / 1327 | time 2788[s] | perplexity 87.01\n",
      "| epoch 4 |  iter 121 / 1327 | time 2802[s] | perplexity 96.40\n",
      "| epoch 4 |  iter 141 / 1327 | time 2816[s] | perplexity 103.85\n",
      "| epoch 4 |  iter 161 / 1327 | time 2830[s] | perplexity 118.78\n",
      "| epoch 4 |  iter 181 / 1327 | time 2843[s] | perplexity 128.23\n",
      "| epoch 4 |  iter 201 / 1327 | time 2857[s] | perplexity 120.43\n",
      "| epoch 4 |  iter 221 / 1327 | time 2870[s] | perplexity 121.54\n",
      "| epoch 4 |  iter 241 / 1327 | time 2884[s] | perplexity 115.58\n",
      "| epoch 4 |  iter 261 / 1327 | time 2898[s] | perplexity 115.14\n",
      "| epoch 4 |  iter 281 / 1327 | time 2911[s] | perplexity 122.59\n",
      "| epoch 4 |  iter 301 / 1327 | time 2924[s] | perplexity 105.63\n",
      "| epoch 4 |  iter 321 / 1327 | time 2938[s] | perplexity 84.00\n",
      "| epoch 4 |  iter 341 / 1327 | time 2952[s] | perplexity 99.93\n",
      "| epoch 4 |  iter 361 / 1327 | time 2965[s] | perplexity 129.36\n",
      "| epoch 4 |  iter 381 / 1327 | time 2979[s] | perplexity 100.07\n",
      "| epoch 4 |  iter 401 / 1327 | time 2992[s] | perplexity 111.52\n",
      "| epoch 4 |  iter 421 / 1327 | time 3005[s] | perplexity 96.06\n",
      "| epoch 4 |  iter 441 / 1327 | time 3021[s] | perplexity 103.52\n",
      "| epoch 4 |  iter 461 / 1327 | time 3044[s] | perplexity 101.15\n",
      "| epoch 4 |  iter 481 / 1327 | time 3058[s] | perplexity 102.76\n",
      "| epoch 4 |  iter 501 / 1327 | time 3072[s] | perplexity 111.14\n",
      "| epoch 4 |  iter 521 / 1327 | time 3086[s] | perplexity 117.82\n",
      "| epoch 4 |  iter 541 / 1327 | time 3100[s] | perplexity 114.30\n",
      "| epoch 4 |  iter 561 / 1327 | time 3115[s] | perplexity 102.84\n",
      "| epoch 4 |  iter 581 / 1327 | time 3129[s] | perplexity 89.64\n",
      "| epoch 4 |  iter 601 / 1327 | time 3142[s] | perplexity 129.08\n",
      "| epoch 4 |  iter 621 / 1327 | time 3155[s] | perplexity 123.31\n",
      "| epoch 4 |  iter 641 / 1327 | time 3169[s] | perplexity 111.71\n",
      "| epoch 4 |  iter 661 / 1327 | time 3182[s] | perplexity 103.72\n",
      "| epoch 4 |  iter 681 / 1327 | time 3195[s] | perplexity 85.55\n",
      "| epoch 4 |  iter 701 / 1327 | time 3208[s] | perplexity 103.49\n",
      "| epoch 4 |  iter 721 / 1327 | time 3222[s] | perplexity 107.64\n",
      "| epoch 4 |  iter 741 / 1327 | time 3236[s] | perplexity 96.93\n",
      "| epoch 4 |  iter 761 / 1327 | time 3250[s] | perplexity 90.28\n",
      "| epoch 4 |  iter 781 / 1327 | time 3265[s] | perplexity 88.41\n",
      "| epoch 4 |  iter 801 / 1327 | time 3279[s] | perplexity 100.48\n",
      "| epoch 4 |  iter 821 / 1327 | time 3293[s] | perplexity 103.10\n",
      "| epoch 4 |  iter 841 / 1327 | time 3307[s] | perplexity 98.71\n",
      "| epoch 4 |  iter 861 / 1327 | time 3320[s] | perplexity 104.46\n",
      "| epoch 4 |  iter 881 / 1327 | time 3334[s] | perplexity 92.76\n",
      "| epoch 4 |  iter 901 / 1327 | time 3348[s] | perplexity 116.15\n",
      "| epoch 4 |  iter 921 / 1327 | time 3362[s] | perplexity 104.86\n",
      "| epoch 4 |  iter 941 / 1327 | time 3375[s] | perplexity 113.49\n",
      "| epoch 4 |  iter 961 / 1327 | time 3388[s] | perplexity 113.26\n",
      "| epoch 4 |  iter 981 / 1327 | time 3401[s] | perplexity 106.81\n",
      "| epoch 4 |  iter 1001 / 1327 | time 3415[s] | perplexity 96.91\n",
      "| epoch 4 |  iter 1021 / 1327 | time 3429[s] | perplexity 113.80\n",
      "| epoch 4 |  iter 1041 / 1327 | time 3442[s] | perplexity 105.13\n",
      "| epoch 4 |  iter 1061 / 1327 | time 3455[s] | perplexity 89.24\n",
      "| epoch 4 |  iter 1081 / 1327 | time 3468[s] | perplexity 79.93\n",
      "| epoch 4 |  iter 1101 / 1327 | time 3481[s] | perplexity 80.32\n",
      "| epoch 4 |  iter 1121 / 1327 | time 3498[s] | perplexity 103.13\n",
      "| epoch 4 |  iter 1141 / 1327 | time 3513[s] | perplexity 100.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 4 |  iter 1161 / 1327 | time 3528[s] | perplexity 90.88\n",
      "| epoch 4 |  iter 1181 / 1327 | time 3543[s] | perplexity 96.03\n",
      "| epoch 4 |  iter 1201 / 1327 | time 3558[s] | perplexity 84.03\n",
      "| epoch 4 |  iter 1221 / 1327 | time 3573[s] | perplexity 75.63\n",
      "| epoch 4 |  iter 1241 / 1327 | time 3587[s] | perplexity 92.10\n",
      "| epoch 4 |  iter 1261 / 1327 | time 3602[s] | perplexity 93.86\n",
      "| epoch 4 |  iter 1281 / 1327 | time 3617[s] | perplexity 89.94\n",
      "| epoch 4 |  iter 1301 / 1327 | time 3631[s] | perplexity 112.01\n",
      "| epoch 4 |  iter 1321 / 1327 | time 3646[s] | perplexity 110.91\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 勾配クリッピングを適用して学習\n",
    "trainer.fit(xs, ts, max_epoch, batch_size, time_size, max_grad, eval_interval=20)\n",
    "trainer.plot(ylim=(0, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating perplexity ...\n",
      "234 / 235\n",
      "test perplexity:  134.17293068722188\n"
     ]
    }
   ],
   "source": [
    "# テストデータで評価\n",
    "model.reset_state()\n",
    "ppl_test = eval_perplexity(model, corpus_test)\n",
    "print('test perplexity: ', ppl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最終的なパープレキシティは110程度であり、最初の10000に比べて大きく減らせている。テストデータでも130程度であり、若干の過学習が生じている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RNNの改善**\\\n",
    "3つの手法がある。\n",
    "1. LSTMレイヤの多層化\\\n",
    "PTBデータセットの言語モデルの場合LSTMレイヤの層数は2~4程度がよい\n",
    "2. Dropoutによる過学習の抑制\\\n",
    "多層にすることで過学習が生じる場合がある。Dropoutはランダムにニューロンを選び、そのニューロンの信号を止めることである。Dropoutレイヤは活性化関数の後に挿入する。今回は深さ方向に対してLSTMレイヤの後に挿入する。変分Dropoutを用いることで時間方向に対してDropoutを適用できる。\n",
    "3. 重み共有\\\n",
    "EmbeddingレイヤとAffineレイヤの重みを結びつける。形状に注意して転置させることが必要。学習させる重みが少なくなるメリットもある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BetterRnnlmの実装**\\\n",
    "基本的にはRnnlmと一緒である。初期化の際のlayersの中身が上述したようになっている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 疑似コード\n",
    "\n",
    "# ~略\n",
    "self.layers = {\n",
    "    TimeEmbedding(embed_W),\n",
    "    TimeDropout(dropout_ratio),\n",
    "    TimeLSTM(lstm_Wx1, lstm_Wh1, lstm_b1, stateful=True),\n",
    "    TimeDropout(dropout_ratio),\n",
    "    TimeLSTM(lstm_Wx2, lstm_Wh2, lstm_b2, stateful=True),\n",
    "    TimeDropout(dropout_ratio),\n",
    "    TimeAffine(embed_W.T, affine_b)\n",
    "}\n",
    "# 略~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注目するのはTimeAffine()の重みである。重み共有をするためembed_Wを渡している。形状を合わせるために転置を行うことに注意"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
